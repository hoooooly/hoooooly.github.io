---
title: 常见的反爬手段和解决思路
tags:
  - 爬虫
comments: true
date: 2021-06-23 18:13:36
categories: 爬虫
index_img:
banner_img:
---

## 服务器反爬的原因

- 爬虫占总PV（PV指页面的访问次数）的比例高，浪费资源。

- 公司可免费查询资源被批量抓走，丧失竞争力。

- 状告爬虫成功的机率小


## 服务器常反什么样的爬虫

- 十分低级的应届生

- 十分低级的创业小公司

- 不小心写错了没人去停止的失控小爬虫

- 成型的商业对手

- 抽风的搜索引擎

## 反爬领域常见的一些概念

- 爬虫：使用任何技术手段，批量获取网站信息的一种方式，关键在于批量

- 反爬虫：使用任何技术手段，阻止别人批量获取自己网站信息的一种方式。关键也是批量。

- 误伤：在反爬虫的过程中，错误的将普通用户识别为爬虫。

- 拦截：成功地阻止爬虫访问。

- 资源：机器成本和人力成本的总和。


## 反爬的三个方向

- 基于身份识别进行反爬

- 基于爬虫行为进行反爬

- 基于数据加密进行反爬

## 常见基于身份识别进行反爬

###  通过headers字段来反爬

1. 通过headers字段中的user-agent进行反爬

- 反爬原理：默认的爬虫没有user-agent
- 解决办法：请求之前添加user-agent即可；最好是使用user-agent池来解决

2. 通过refer字段或其他字段来反爬

- 反爬原理：爬虫默认情况下是不会携带refer字段的，服务器通过判断请求发起的源头，以此判断请求是否合法
- 解决方法：添加refer字段

3. 通过cookie来反爬

- 反爬原因：通过检查cookie来查看发起请求的用户是否具备相应权限
- 解决方案：进行模拟登录，成功获取cookies之后进行数据爬取





     




[//]:#(设置表格整体居中显示)
<style>
    table
    {
        margin: auto;
        font-size: 80%;
    }
</style>


